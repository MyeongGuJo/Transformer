# Transformer

- using colab
- heads of MultiHeadAttention = 1
- \# of encoder layers = 1
- \# of decoder layers = 1
