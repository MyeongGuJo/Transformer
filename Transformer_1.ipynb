{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DAhSsj-1FqrnVoVJA9d8T3a4_YcL-cqc",
      "authorship_tag": "ABX9TyOn/yTu5lMY1roNWOJPS3Ng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyeongGuJo/Transformer/blob/main/Transformer_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vczM8tzAJaJ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kvrXsAA6ANsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, dim, device):\n",
        "    super().__init__()\n",
        "    self.q_proj = nn.Linear(dim, dim, device=device)\n",
        "    self.k_proj = nn.Linear(dim, dim, device=device)\n",
        "    self.v_proj = nn.Linear(dim, dim, device=device)\n",
        "\n",
        "  def forward(self, Q, K, V, padding_mask, causal_mask = None):\n",
        "    query = self.q_proj(Q)\n",
        "    key = self.k_proj(K)\n",
        "    value = self.v_proj(V)\n",
        "\n",
        "    # Q.shape = bs * seq_len * dim\n",
        "\n",
        "    bs = query.shape[0]\n",
        "\n",
        "    energy = query.matmul(key.transpose(-1, -2))\n",
        "\n",
        "    # scaling\n",
        "    d_k = key.size(-1)**(1/2)\n",
        "    energy = energy / d_k\n",
        "\n",
        "    mask = padding_mask.unsqueeze(1)\n",
        "\n",
        "    if causal_mask is not None:\n",
        "      mask = mask * causal_mask\n",
        "\n",
        "    energy = energy.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "    output = F.softmax(energy, -1)\n",
        "    output = output.matmul(value)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "m60ZeFAmQhoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, d, device):\n",
        "    super().__init__()\n",
        "    self.inner_proj = nn.Linear(d, d*4, bias=False, device=device)\n",
        "    self.outer_proj = nn.Linear(d*4, d, bias=False, device=device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    inner = self.inner_proj(x)\n",
        "    output = F.relu(inner)\n",
        "\n",
        "    output = self.outer_proj(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "kuOIk_K2VS3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, dim, max_seq_len, device):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=dim, padding_idx=0, device=device)\n",
        "    self.pos_embedding = nn.Embedding(128, dim, device=device) # max_length = 128\n",
        "    self.max_seq_len = max_seq_len\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(dim, device=device)\n",
        "\n",
        "    self.self_attention = Attention(dim, device=device)\n",
        "\n",
        "    self.feed_forward = FeedForward(dim, device=device)\n",
        "\n",
        "    #self.device = device\n",
        "    self.register_buffer('pos', torch.arange(0, self.max_seq_len).to(device))\n",
        "\n",
        "  def forward(self, input, input_mask):\n",
        "    input_pos = self.pos\n",
        "    input_seq = self.embedding(input) + self.pos_embedding(input_pos)\n",
        "\n",
        "    # self attention\n",
        "    residual = input_seq\n",
        "    output = self.self_attention(input_seq, input_seq, input_seq, input_mask)\n",
        "\n",
        "    # Add & Norm\n",
        "    output = self.layer_norm(output)\n",
        "    output = residual + output\n",
        "\n",
        "    # Feed Forward\n",
        "    residual = output\n",
        "    output = self.feed_forward(output)\n",
        "\n",
        "    # Add & Norm\n",
        "    output = residual + output\n",
        "    output = self.layer_norm(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "XO8BTtWBa2px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocab_size, dim, max_seq_len, device):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=dim, padding_idx=0, device=device)\n",
        "    self.pos_embedding = nn.Embedding(max_seq_len, dim, device=device) # max_length = 128\n",
        "    self.max_seq_len = max_seq_len\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(dim, device=device)\n",
        "\n",
        "    self.self_attention = Attention(dim, device=device)\n",
        "    self.cross_attention = Attention(dim, device=device)\n",
        "\n",
        "    self.feed_forward = FeedForward(dim, device=device)\n",
        "\n",
        "    self.out_proj = nn.Linear(dim, vocab_size, device=device)\n",
        "\n",
        "    self.device = device\n",
        "    self.register_buffer('pos', torch.arange(0, self.max_seq_len).to(device))\n",
        "\n",
        "  def forward(self, input, input_mask, enc_output):\n",
        "    input_pos = self.pos\n",
        "    input_seq = self.embedding(input) + self.pos_embedding(input_pos)\n",
        "\n",
        "    # mask (bs == 16)\n",
        "    bs, dim = input.shape\n",
        "    m = torch.tril(torch.ones(bs, self.max_seq_len, dim, dtype=int)).to(self.device)\n",
        "\n",
        "    # self attention\n",
        "    residual = input_seq\n",
        "    output = self.self_attention(input_seq, input_seq, input_seq, input_mask, causal_mask=m)\n",
        "\n",
        "    # Add & Norm\n",
        "    output = self.layer_norm(output)\n",
        "    output = residual + output\n",
        "\n",
        "    # cross attention\n",
        "    residual = output\n",
        "    output = self.cross_attention(output, enc_output, enc_output, input_mask, causal_mask=m)\n",
        "\n",
        "    # Add & Norm\n",
        "    output = residual + output\n",
        "    output = self.layer_norm(output)\n",
        "\n",
        "    # Feed Forward\n",
        "    residual = output\n",
        "    output = self.feed_forward(output)\n",
        "\n",
        "    # Add & Norm\n",
        "    output = residual + output\n",
        "    output = self.layer_norm(output)\n",
        "\n",
        "\n",
        "    # Linear & Softmax\n",
        "    logits = self.out_proj(output)\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "hGknRpFeJNGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, vocab_size, input_dim, output_dim, max_seq_len, device):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(vocab_size, input_dim, max_seq_len, device)\n",
        "    self.decoder = Decoder(vocab_size, output_dim, max_seq_len, device)\n",
        "\n",
        "  def forward(self, enc_src, enc_mask, dec_src, dec_mask):\n",
        "    # enc_src: (bs, seq_len)\n",
        "    # dec_src: (bs, seq_len)\n",
        "\n",
        "    enc_output = self.encoder(enc_src , enc_mask)\n",
        "    logits = self.decoder(dec_src, dec_mask, enc_output)\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "IHtV_y_jFDoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "encoded = tokenizer('I am an undergraduated', return_tensors='pt')\n",
        "print(encoded)"
      ],
      "metadata": {
        "id": "MgYkusiAAO3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "import pandas as pd\n",
        "\n",
        "excel_file = pd.read_excel('/content/drive/MyDrive/kor_eng_excel_dataset/2_대화체_190920.xlsx')\n",
        "kor_dataset = list(excel_file['한국어'].values)\n",
        "eng_dataset = list(excel_file['영어'].values)"
      ],
      "metadata": {
        "id": "QIor6rsJ_WVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_dataset[:5]"
      ],
      "metadata": {
        "id": "iXb4D4KeABM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_kor = tokenizer(kor_dataset, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
        "encoded_eng = tokenizer(eng_dataset, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "train_data = encoded_kor['input_ids']\n",
        "train_mask = encoded_kor['attention_mask']\n",
        "target_data = encoded_eng['input_ids']\n",
        "target_mask = encoded_eng['attention_mask']"
      ],
      "metadata": {
        "id": "m0g1eaD-tZDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "id": "Eckf3h0PP1kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.vocab), train_mask.shape, target_mask.shape"
      ],
      "metadata": {
        "id": "r94e12kO0TiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_kor['input_ids'].shape, encoded_eng['input_ids'].shape[-1]"
      ],
      "metadata": {
        "id": "6pXrASsZtuCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.vocab)\n",
        "input_dim = 256\n",
        "output_dim = 256\n",
        "max_seq_len = 128\n",
        "batch_size = 64\n",
        "LEARNING_RATE = 0.0005\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "vyG63MQLEFIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(vocab_size, input_dim, output_dim, max_seq_len, device)"
      ],
      "metadata": {
        "id": "VcS4z9DDIHjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize model parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "opayhn-DJNJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "metadata": {
        "id": "btolLBdKJV4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "CEL_loss = nn.CrossEntropyLoss(ignore_index=0)"
      ],
      "metadata": {
        "id": "o58DmDSaJg-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, input_dim, output_dim"
      ],
      "metadata": {
        "id": "gNBX_RxrzW8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0].shape"
      ],
      "metadata": {
        "id": "6c000oc2EU1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_it = train_data.shape[0]"
      ],
      "metadata": {
        "id": "6ChNCn-Fve2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_shift_left(input_ids):\n",
        "  bs = input_ids.shape[0]\n",
        "  new_input_ids = input_ids[:, 1:] # 256->255\n",
        "  new_input_ids = torch.cat((new_input_ids, torch.LongTensor([[0] for _ in range(bs)]).to(device)), -1)\n",
        "\n",
        "  return new_input_ids"
      ],
      "metadata": {
        "id": "B0EFubrqVQs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = TensorDataset(train_data, train_mask, target_data, target_mask)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "66dujkqBRb_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  # gradient descent\n",
        "  for i, samples in enumerate(dataloader):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    src, src_mask, trg, trg_mask = samples\n",
        "\n",
        "    src = src.to(device)\n",
        "    src_mask = src_mask.to(device)\n",
        "    trg = trg.to(device)\n",
        "    trg_mask = trg_mask.to(device)\n",
        "\n",
        "    trg_shifted = label_shift_left(trg)\n",
        "    mask_shifted = label_shift_left(trg_mask)\n",
        "\n",
        "    logits = model(src,\n",
        "                   src_mask,\n",
        "                   trg,\n",
        "                   trg_mask\n",
        "                   )\n",
        "\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    trg_shifted = trg_shifted.reshape(-1)\n",
        "    loss = CEL_loss(logits,trg_shifted)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "    # print(f'loss: {loss.item()}')\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch: {epoch} | Train Loss: {epoch_loss / len(dataloader)}')\n",
        "\n",
        "  for i, param in enumerate(model.parameters()):\n",
        "    if i == 5:\n",
        "      break\n",
        "    print(param.reshape(-1)[:5])\n",
        "  print('')"
      ],
      "metadata": {
        "id": "GpzMdd7EHUiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "id": "wrnXz1Mq_4aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "input_seq = '어제 수업에 가지 못했는데 다음 수업 때 필요한게 있을까요?'\n",
        "\n",
        "encoded =  tokenizer(input_seq,\n",
        "                    return_tensors='pt',\n",
        "                    padding='max_length',\n",
        "                    truncation=True,\n",
        "                    max_length=max_seq_len\n",
        "                    )\n",
        "\n",
        "input_ids = encoded['input_ids'].unsqueeze(0).to(device)\n",
        "input_mask = encoded['attention_mask'].unsqueeze(0).to(device)\n",
        "\n",
        "default_ids = torch.LongTensor([101]).unsqueeze(0).to(device) # start of sentence token ids\n",
        "default_mask = torch.LongTensor([1]).unsqueeze(0).to(device)\n",
        "\n",
        "for i in range(1, max_seq_len):\n",
        "  pad_ids = torch.LongTensor([0 for _ in range(max_seq_len-i)]).unsqueeze(0).to(device)\n",
        "  output_ids = torch.cat((default_ids, pad_ids), -1)\n",
        "\n",
        "  pad_mask = torch.LongTensor([0 for _ in range(max_seq_len-i)]).unsqueeze(0).to(device)\n",
        "  output_mask = torch.cat((default_mask, pad_mask), -1)\n",
        "\n",
        "  logits = model(input_ids, input_mask, output_ids, output_mask)\n",
        "\n",
        "  logits = F.softmax(logits, -1)\n",
        "  next_token_id = torch.argmax(logits, -1)[0][0][i]\n",
        "\n",
        "  if next_token_id == 102: # end of sentence token\n",
        "    break\n",
        "\n",
        "  default_ids = torch.cat((default_ids, next_token_id.unsqueeze(0).unsqueeze(0)), -1)\n",
        "  default_mask = torch.cat((default_mask, torch.LongTensor([[1]]).to(device)), -1)\n",
        "\n",
        "input_seq, ''.join(tokenizer.batch_decode(output_ids, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "S6_H1GJdoXe1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}